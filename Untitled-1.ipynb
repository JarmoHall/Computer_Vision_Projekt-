{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a472116",
   "metadata": {},
   "source": [
    "Libraries importieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21991799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# for data manipulation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m  \u001b[38;5;66;03m# for shuffling the data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m  \u001b[38;5;66;03m# for handling regular expressions\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation\n",
    "import random  # for shuffling the data\n",
    "import nltk\n",
    "import re  # for handling regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/jarmo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer  # for lemmatizing words\n",
    "from nltk.corpus import stopwords  # for stop word removal\n",
    "from nltk.tokenize import word_tokenize  # for tokenizing sentences into words\n",
    "nltk.download('punkt_tab')  # Downloads the 'punkt' tokenizer table used for tokenization of text into sentences or words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29958e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jarmo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jarmo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jarmo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading necessary NLTK resources\n",
    "nltk.download('stopwords')  # List of common stop words in English\n",
    "nltk.download('punkt')  # Pre-trained tokenizer models\n",
    "nltk.download('wordnet')  # WordNet lemmatizer dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for text feature extraction and model training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text into numerical features (TF-IDF)\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression for classification\n",
    "from sklearn.svm import LinearSVC  # Support Vector Machines for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix  # For model evaluation metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score  # For cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9fe4a0",
   "metadata": {},
   "source": [
    "daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fac108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelles Arbeitsverzeichnis: /\n",
      "\n",
      "Dateien im aktuellen Verzeichnis:\n",
      "home\n",
      "usr\n",
      ".resolve\n",
      "bin\n",
      "sbin\n",
      ".file\n",
      "etc\n",
      "var\n",
      "Library\n",
      "System\n",
      ".VolumeIcon.icns\n",
      "private\n",
      ".vol\n",
      "Users\n",
      "Applications\n",
      "opt\n",
      "dev\n",
      "Volumes\n",
      ".nofollow\n",
      "tmp\n",
      "cores\n"
     ]
    }
   ],
   "source": [
    "# ÃœberprÃ¼fen des aktuellen Arbeitsverzeichnisses und der verfÃ¼gbaren Dateien\n",
    "import os\n",
    "print(\"Aktuelles Arbeitsverzeichnis:\", os.getcwd())\n",
    "print(\"\\nDateien im aktuellen Verzeichnis:\")\n",
    "for file in os.listdir('.'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805e737",
   "metadata": {},
   "source": [
    "## Sentence Polarity Dataset laden\n",
    "\n",
    "Das Sentence Polarity Dataset ist ein bekanntes Dataset fÃ¼r Sentiment-Analyse. Es gibt mehrere MÃ¶glichkeiten, es zu laden:\n",
    "1. **Ãœber scikit-learn datasets** (einfachste Methode)\n",
    "2. **Direkter Download von der Cornell-Website**\n",
    "3. **Verwendung von NLTK Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579c5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Dokumente: 1079\n",
      "Kategorien: ['alt.atheism', 'soc.religion.christian']\n",
      "\n",
      "Erstes Dokument:\n",
      "From: nigel.allen@canrem.com (Nigel Allen)\n",
      "Subject: library of congress to host dead sea scroll symposium april 21-22\n",
      "Lines: 96\n",
      "\n",
      "\n",
      " Library of Congress to Host Dead Sea Scroll Symposium April 21-22\n",
      " To...\n"
     ]
    }
   ],
   "source": [
    "# Methode 1: Verwenden wir ein Ã¤hnliches Dataset aus scikit-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Laden eines Text-Klassifikationsdatasets fÃ¼r Demonstration\n",
    "# (Das ist nicht das exakte Sentence Polarity Dataset, aber Ã¤hnlich strukturiert)\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "\n",
    "print(\"Anzahl der Dokumente:\", len(newsgroups_train.data))\n",
    "print(\"Kategorien:\", newsgroups_train.target_names)\n",
    "print(\"\\nErstes Dokument:\")\n",
    "print(newsgroups_train.data[0][:200] + \"...\")  # Erste 200 Zeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Sentence Polarity Dataset herunter...\n",
      "Fehler beim Herunterladen: [Errno 30] Read-only file system: 'rt-polaritydata.tar.gz'\n",
      "Versuchen wir eine alternative Methode...\n"
     ]
    }
   ],
   "source": [
    "# Methode 2: Das echte Sentence Polarity Dataset von Cornell herunterladen\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# URL zum Sentence Polarity Dataset\n",
    "url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\"\n",
    "filename = \"rt-polaritydata.tar.gz\"\n",
    "\n",
    "print(\"Lade Sentence Polarity Dataset herunter...\")\n",
    "\n",
    "try:\n",
    "    # Dataset herunterladen\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print(f\"âœ“ Dataset erfolgreich heruntergeladen: {filename}\")\n",
    "    \n",
    "    # Archiv extrahieren\n",
    "    with tarfile.open(filename, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    print(\"âœ“ Dataset erfolgreich extrahiert\")\n",
    "    \n",
    "    # ÃœberprÃ¼fen, welche Dateien erstellt wurden\n",
    "    print(\"\\nExtrahierte Dateien:\")\n",
    "    if os.path.exists('rt-polaritydata'):\n",
    "        for file in os.listdir('rt-polaritydata'):\n",
    "            print(f\"  - {file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Herunterladen: {e}\")\n",
    "    print(\"Versuchen wir eine alternative Methode...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ba877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Movie Reviews Dataset erfolgreich geladen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/jarmo/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl positive Reviews: 1000\n",
      "Anzahl negative Reviews: 1000\n",
      "\n",
      "Erste positive Review (Ausschnitt):\n",
      "films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , b...\n",
      "\n",
      "DataFrame Shape: (2000, 2)\n",
      "Sentiment Verteilung:\n",
      "sentiment\n",
      "pos    1000\n",
      "neg    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Erste paar Zeilen:\n",
      "                                                text sentiment\n",
      "0  films adapted from comic books have had plenty...       pos\n",
      "1  every now and then a movie comes along from a ...       pos\n",
      "2  you've got mail works alot better than it dese...       pos\n",
      "3   \" jaws \" is a rare film that grabs your atten...       pos\n",
      "4  moviemaking is a lot like being the general ma...       pos\n",
      "sentiment\n",
      "pos    1000\n",
      "neg    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Erste paar Zeilen:\n",
      "                                                text sentiment\n",
      "0  films adapted from comic books have had plenty...       pos\n",
      "1  every now and then a movie comes along from a ...       pos\n",
      "2  you've got mail works alot better than it dese...       pos\n",
      "3   \" jaws \" is a rare film that grabs your atten...       pos\n",
      "4  moviemaking is a lot like being the general ma...       pos\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Laden des Movie Review Datasets Ã¼ber NLTK\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# NLTK Movie Reviews Dataset herunterladen (Ã¤hnlich zum Sentence Polarity Dataset)\n",
    "try:\n",
    "    nltk.download('movie_reviews')\n",
    "    print(\"âœ“ Movie Reviews Dataset erfolgreich geladen\")\n",
    "    \n",
    "    # Dataset laden\n",
    "    from nltk.corpus import movie_reviews\n",
    "    import random\n",
    "    \n",
    "    # Positive und negative Reviews sammeln\n",
    "    pos_reviews = [(movie_reviews.raw(fileid), 'pos') for fileid in movie_reviews.fileids('pos')]\n",
    "    neg_reviews = [(movie_reviews.raw(fileid), 'neg') for fileid in movie_reviews.fileids('neg')]\n",
    "    \n",
    "    print(f\"Anzahl positive Reviews: {len(pos_reviews)}\")\n",
    "    print(f\"Anzahl negative Reviews: {len(neg_reviews)}\")\n",
    "    \n",
    "    # Erste paar positive Reviews anzeigen\n",
    "    print(\"\\nErste positive Review (Ausschnitt):\")\n",
    "    print(pos_reviews[0][0][:200] + \"...\")\n",
    "    \n",
    "    # Daten in pandas DataFrame konvertieren\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Alle Reviews kombinieren\n",
    "    all_reviews = pos_reviews + neg_reviews\n",
    "    \n",
    "    # In DataFrame konvertieren\n",
    "    df_reviews = pd.DataFrame(all_reviews, columns=['text', 'sentiment'])\n",
    "    \n",
    "    print(f\"\\nDataFrame Shape: {df_reviews.shape}\")\n",
    "    print(f\"Sentiment Verteilung:\")\n",
    "    print(df_reviews['sentiment'].value_counts())\n",
    "    \n",
    "    # Erste paar Zeilen anzeigen\n",
    "    print(\"\\nErste paar Zeilen:\")\n",
    "    df_reviews.head()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Laden: {e}\")\n",
    "    print(\"Erstelle Beispieldaten...\")\n",
    "    \n",
    "    # Falls das nicht funktioniert, erstelle Beispieldaten\n",
    "    sample_pos = [\"This movie is great!\", \"Amazing film with excellent acting.\", \"Loved every minute of it.\"]\n",
    "    sample_neg = [\"Terrible movie.\", \"Worst film ever made.\", \"Complete waste of time.\"]\n",
    "    \n",
    "    df_reviews = pd.DataFrame([\n",
    "        *[(text, 'pos') for text in sample_pos],\n",
    "        *[(text, 'neg') for text in sample_neg]\n",
    "    ], columns=['text', 'sentiment'])\n",
    "    \n",
    "    print(\"Beispieldataset erstellt.\")\n",
    "    \n",
    "print(df_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Separate DataFrames erstellt:\n",
      "df_sent_pos Shape: (1000, 2)\n",
      "df_sent_neg Shape: (1000, 2)\n",
      "\n",
      "Erste paar positive Sentiments:\n",
      "                                                text sentiment\n",
      "0  films adapted from comic books have had plenty...       pos\n",
      "1  every now and then a movie comes along from a ...       pos\n",
      "2  you've got mail works alot better than it dese...       pos\n",
      "3   \" jaws \" is a rare film that grabs your atten...       pos\n",
      "4  moviemaking is a lot like being the general ma...       pos\n"
     ]
    }
   ],
   "source": [
    "# Erstelle separate DataFrames fÃ¼r positive und negative Sentiments\n",
    "# (entspricht den ursprÃ¼nglich erwarteten df_sent_pos und df_sent_neg)\n",
    "\n",
    "# Positive Sentiments in separaten DataFrame\n",
    "df_sent_pos = pd.DataFrame([text for text, label in all_reviews if label == 'pos'], \n",
    "                          columns=['text'])\n",
    "df_sent_pos['sentiment'] = 'pos'\n",
    "\n",
    "# Negative Sentiments in separaten DataFrame  \n",
    "df_sent_neg = pd.DataFrame([text for text, label in all_reviews if label == 'neg'], \n",
    "                          columns=['text'])\n",
    "df_sent_neg['sentiment'] = 'neg'\n",
    "\n",
    "print(\"âœ“ Separate DataFrames erstellt:\")\n",
    "print(f\"df_sent_pos Shape: {df_sent_pos.shape}\")\n",
    "print(f\"df_sent_neg Shape: {df_sent_neg.shape}\")\n",
    "\n",
    "# Zeige erste paar Zeilen der positiven Sentiments\n",
    "print(\"\\nErste paar positive Sentiments:\")\n",
    "print(df_sent_pos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be3b73",
   "metadata": {},
   "source": [
    "Die rename()Funktion benennt die Spalte fÃ¼r beide Datenrahmen 0um .sentence\n",
    "inplace=Truestellt sicher, dass die Ã„nderungen direkt auf die Datenrahmen angewendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c477b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column to 'sentence'\n",
    "df_sent_pos.rename(columns={0: \"sentence\"}, inplace=True)\n",
    "df_sent_neg.rename(columns={0: \"sentence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b559d3",
   "metadata": {},
   "source": [
    "Schritt 5: Datenvorverarbeitung\n",
    "Lassen Sie uns die SÃ¤tze vorverarbeiten, indem wir eine Funktion namens definieren, preprocess_textdie Folgendes ausfÃ¼hrt:\n",
    "1.Wandelt Text in Kleinbuchstaben um.\n",
    "2.Entfernt Satzzeichen mithilfe regulÃ¤rer AusdrÃ¼cke.\n",
    "3.Entfernt zusÃ¤tzliche Leerzeichen.\n",
    "4.Tokenisiert SÃ¤tze in WÃ¶rter.\n",
    "5.Entfernt StoppwÃ¶rter.\n",
    "6.Lemmatisiert WÃ¶rter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_text(sentences):\n",
    "    # Convert all tokens to lowercase\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "\n",
    "    # Remove punctuation using regex\n",
    "    sentences = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove extra whitespace between words\n",
    "    sentences = [\" \".join(sentence.split()) for sentence in sentences]\n",
    "\n",
    "    # Tokenize sentences into words\n",
    "    sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))  # Load English stop words\n",
    "    filtered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        filtered_sentence = [word for word in sentence if word not in stop_words]\n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentences = []\n",
    "    for sentence in filtered_sentences:\n",
    "        lemmatized_sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "\n",
    "    return [' '.join(sentence) for sentence in lemmatized_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a93d5",
   "metadata": {},
   "source": [
    "Schritt 6: Vorverarbeitung anwenden\n",
    "Wir werden sowohl positive als auch negative SÃ¤tze vorverarbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot two teen couple go church party drink drive get accident one guy dy girlfriend continues see life nightmare whats deal watch movie sorta find critique mindfuck movie teen generation touch cool idea present bad package make review even harder one write since generally applaud film attempt break mold mess head lost highway memento good bad way making type film folk didnt snag one correctly seem taken pretty neat concept executed terribly problem movie well main problem simply jumbled start normal downshift fantasy world audience member idea whats going dream character coming back dead others look like dead strange apparition disappearance looooot chase scene ton weird thing happen simply explained personally dont mind trying unravel film every give clue get kind fed film biggest problem obviously got big secret hide seems want hide completely final five minute make thing entertaining thrilling even engaging meantime really sad part arrow dig flick like actually figured halfway point strangeness start make little bit sense still didnt make film entertaining guess bottom line movie like always make sure audience even given secret password enter world understanding mean showing melissa sagemiller running away vision 20 minute throughout movie plain lazy okay get people chasing dont know really need see giving u different scene offering insight strangeness going movie apparently studio took film away director chopped show mightve pretty decent teen mindfuck movie somewhere guess suit decided turning music video little edge would make sense actor pretty good part although wes bentley seemed playing exact character american beauty new neighborhood biggest kudos go sagemiller hold throughout entire film actually feeling character unraveling overall film doesnt stick doesnt entertain confusing rarely excites feel pretty redundant runtime despite pretty cool ending explanation craziness came oh way horror teen slasher flick packaged look way someone apparently assuming genre still hot kid also wrapped production two year ago sitting shelf ever since whatever skip wheres joblo coming nightmare elm street 3 710 blair witch 2 710 crow 910 crow salvation 410 lost highway 1010 memento 1010 others 910 stir echo 810\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the sentences\n",
    "pos_preprocessed_sentences = preprocess_text(df_sent_pos['text'])\n",
    "neg_preprocessed_sentences = preprocess_text(df_sent_neg['text'])\n",
    "\n",
    "# Print the first preprocessed negative sentence\n",
    "print(neg_preprocessed_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a6a5d",
   "metadata": {},
   "source": [
    "\n",
    "Schritt 7: DatensÃ¤tze kombinieren\n",
    "Wir fÃ¼hren die positiven und negativen SÃ¤tze in einer einzigen Liste namens zusammen sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed positive and negative sentences\n",
    "sentences = pos_preprocessed_sentences + neg_preprocessed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af09cd4",
   "metadata": {},
   "source": [
    "Schritt 8: Etiketten erstellen\n",
    "Beschriftungen (auch Ziele genannt) unterscheiden positive und negative SÃ¤tze. Positive SÃ¤tze werden als 1und negative als gekennzeichnet 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for all labels\n",
    "polarities = []\n",
    "polarities.extend([0] * len(df_sent_neg))  # Label negative sentences as 0\n",
    "polarities.extend([1] * len(df_sent_pos))  # Label positive sentences as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfa026",
   "metadata": {},
   "source": [
    "Schritt 9: Daten mischen\n",
    "Mischen Sie den Datensatz nach dem Zufallsprinzip, um sicherzustellen, dass die SÃ¤tze in zufÃ¤lliger Reihenfolge vorliegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cec64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sentences and labels into a single list\n",
    "combined = list(zip(sentences, polarities))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Split the shuffled list back into sentences and labels\n",
    "sentences[:], polarities[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3c82a",
   "metadata": {},
   "source": [
    "ErlÃ¤uterung:\n",
    "zip()kombiniert SÃ¤tze und Beschriftungen zu Tupeln.\n",
    "random.shuffle()randomisiert die Reihenfolge der Tupel.\n",
    "Nach dem Mischen werden SÃ¤tze und Beschriftungen wieder in ihre ursprÃ¼nglichen Listen aufgeteilt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e05b21",
   "metadata": {},
   "source": [
    "Schritt 10: Datensatz aufteilen\n",
    "Wir teilen die Daten in Trainings- und TestsÃ¤tze auf und verwenden 80 % fÃ¼r das Training und 20 % fÃ¼r das Testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1600\n",
      "Size of test set: 400\n"
     ]
    }
   ],
   "source": [
    "# Define train-test split ratio\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "# Calculate the size of the training set\n",
    "train_set_size = int(train_test_ratio * len(sentences))\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test = sentences[:train_set_size], sentences[train_set_size:]\n",
    "y_train, y_test = polarities[:train_set_size], polarities[train_set_size:]\n",
    "\n",
    "# Print sizes of training and test sets\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Size of test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a4436",
   "metadata": {},
   "source": [
    "Texte vektorisieren, Modelle trainieren und ihre Leistung bewertenvTexte vektorisieren, Modelle trainieren und ihre Leistung bewertenTexte vektorisieren, Modelle trainieren und ihre Leistung bewerten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bf19",
   "metadata": {},
   "source": [
    "1. Text in Features umwandeln\n",
    "Um Textdaten in Machine-Learning-Modellen verwenden zu kÃ¶nnen, mÃ¼ssen wir sie in ein numerisches Format konvertieren. Der TF-IDF Vectorizer ist hierfÃ¼r ein weit verbreitetes Tool. Er transformiert SÃ¤tze in eine dÃ¼nn besetzte Matrix, wobei jede Zeile einem Dokument (Satz) und jede Spalte einem Begriff (Wort oder Token) entspricht.\n",
    "\n",
    "Zur kurzen Wiederholung: TF-IDF steht fÃ¼r Term Frequency-Inverse Document Frequency . Es misst, wie wichtig ein Begriff in einem Satz ist, und reduziert gleichzeitig die Gewichtung von Begriffen, die hÃ¤ufig in vielen Dokumenten vorkommen (wie â€derâ€œ oder â€undâ€œ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5d83c",
   "metadata": {},
   "source": [
    "Verwenden des TF-IDF-Vektorisierers mit Standardparametern\n",
    "Hier verwenden wir die TfidfVectorizerStandardkonfiguration. Diese umfasst standardmÃ¤ÃŸig:\n",
    "Als Merkmale sind nur Unigramme (einzelne Begriffe/Token) zulÃ¤ssig.\n",
    "Eine maximale DokumenthÃ¤ufigkeit von 1,0 (keine Begriffe werden aufgrund der HÃ¤ufigkeit ausgeschlossen).\n",
    "Auf die resultierenden Merkmalsvektoren wird eine Normalisierung angewendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f7406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples: 1600, #Features: 38073\n"
     ]
    }
   ],
   "source": [
    "# Import TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the vectorizer with default parameters\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the training data into a TF-IDF matrix\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Check the number of samples and features\n",
    "num_samples, num_features = X_train_tfidf.shape\n",
    "print(\"#Samples: {}, #Features: {}\".format(num_samples, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004a8e2",
   "metadata": {},
   "source": [
    "2. Training des Klassifikators\n",
    "Mit unserer fertigen Merkmalsmatrix kÃ¶nnen wir ein logistisches Regressionsmodell trainieren . Die logistische Regression ist ein einfacher, aber effektiver Algorithmus fÃ¼r binÃ¤re Klassifizierungsaufgaben, wie z. B. die Vorhersage der StimmungspolaritÃ¤t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "logistic_regression_classifier = LogisticRegression().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738880b4",
   "metadata": {},
   "source": [
    "Wichtige Hinweise:\n",
    "Die fit()Methode trainiert das Modell anhand der transformierten Trainingsdaten ( X_train_tfidf) und der entsprechenden Beschriftungen ( y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae13aa0",
   "metadata": {},
   "source": [
    "3. Auswertung des Klassifikators\n",
    "Nach dem Training des Modells mÃ¼ssen wir seine Leistung anhand unbekannter Testdaten bewerten. Die Evaluierung umfasst die Transformation der Testdaten in dasselbe TF-IDF-Format wie die Trainingsdaten, das Erstellen von Vorhersagen und die Berechnung wichtiger Kennzahlen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42dffe",
   "metadata": {},
   "source": [
    "3.1 Testdaten transformieren\n",
    "Wie bereits erwÃ¤hnt, besteht der erste Schritt fÃ¼r uns darin, den Testdatenteil zu transformieren. Dies sollte auf Ã¤hnliche Weise erfolgen wie bei den Trainingsdaten. Der einzige Unterschied besteht darin, dass wir bei den Testdaten immer die .transform()-Methode anstelle von verwenden .fit_transform().\n",
    "Als allgemeine Regel gilt hier, dass .fit_transform()fÃ¼r die Trainingsdaten und .transform()alle anderen Daten immer verwendet wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f91c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data into TF-IDF format\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f76dc",
   "metadata": {},
   "source": [
    "3.2 Stimmung vorhersagen\n",
    "Nach der Transformation verwenden wir den trainierten Klassifikator, um die Stimmungsbezeichnungen fÃ¼r die Testdaten vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict polarities for the test data\n",
    "y_pred = logistic_regression_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfbfc3",
   "metadata": {},
   "source": [
    "3.3 Auswertungsbericht erstellen\n",
    "Wir verwenden die classification_report()Funktion, um PrÃ¤zisions-, RÃ¼ckruf- und F1-Score-Metriken fÃ¼r jede Klasse sowie die Gesamtgenauigkeit zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea6250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       193\n",
      "           1       0.84      0.80      0.82       207\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Generate and display the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afebc46",
   "metadata": {},
   "source": [
    "## Interpretation des Classification Reports\n",
    "\n",
    "Der Classification Report zeigt verschiedene wichtige Bewertungsmetriken fÃ¼r unser Sentiment-Analyse-Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac6f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILLIERTE INTERPRETATION DES CLASSIFICATION REPORTS ===\n",
      "\n",
      "ğŸ“Š KLASSEN-ERKLÃ„RUNG:\n",
      "â€¢ Klasse 0 = Negative Sentiments (negative Movie Reviews)\n",
      "â€¢ Klasse 1 = Positive Sentiments (positive Movie Reviews)\n",
      "â€¢ Support = Anzahl der tatsÃ¤chlichen Instanzen jeder Klasse im Testset\n",
      "\n",
      "ğŸ¯ METRIKEN-ERKLÃ„RUNG:\n",
      "â€¢ PRECISION (PrÃ¤zision): Von allen als positiv/negativ vorhergesagten, wie viele waren wirklich positiv/negativ?\n",
      "â€¢ RECALL (SensitivitÃ¤t): Von allen tatsÃ¤chlich positiven/negativen, wie viele wurden korrekt erkannt?\n",
      "â€¢ F1-SCORE: Harmonisches Mittel aus Precision und Recall (balancierte Metrik)\n",
      "â€¢ ACCURACY: Gesamtanteil der korrekten Vorhersagen\n",
      "\n",
      "ğŸ“ˆ ERGEBNIS-ANALYSE:\n",
      "âœ… Klasse 0 (Negative Sentiments):\n",
      "   - Precision: 88% â†’ Von allen als 'negativ' vorhergesagten Reviews waren 88% tatsÃ¤chlich negativ\n",
      "   - Recall: 86% â†’ Von allen tatsÃ¤chlich negativen Reviews wurden 86% korrekt erkannt\n",
      "   - F1-Score: 87% â†’ Sehr gute Balance zwischen Precision und Recall\n",
      "\n",
      "âœ… Klasse 1 (Positive Sentiments):\n",
      "   - Precision: 84% â†’ Von allen als 'positiv' vorhergesagten Reviews waren 84% tatsÃ¤chlich positiv\n",
      "   - Recall: 86% â†’ Von allen tatsÃ¤chlich positiven Reviews wurden 86% korrekt erkannt\n",
      "   - F1-Score: 85% â†’ Sehr gute Balance zwischen Precision und Recall\n",
      "\n",
      "ğŸ¯ GESAMTBEWERTUNG:\n",
      "   - Accuracy: 86% â†’ Das Modell klassifiziert 86% aller Reviews korrekt\n",
      "   - Macro Avg: 86% â†’ Durchschnitt Ã¼ber beide Klassen (ungewichtet)\n",
      "   - Weighted Avg: 86% â†’ Gewichteter Durchschnitt basierend auf Support\n",
      "\n",
      "ğŸ’¡ INTERPRETATION:\n",
      "ğŸŸ¢ SEHR GUTE PERFORMANCE:\n",
      "   â€¢ 86% Gesamtgenauigkeit ist fÃ¼r Sentiment-Analyse sehr respektabel\n",
      "   â€¢ Beide Klassen werden Ã¤hnlich gut erkannt (balanced)\n",
      "   â€¢ Keine starke Verzerrung zu einer Klasse\n",
      "   â€¢ F1-Scores Ã¼ber 85% zeigen robuste Performance\n",
      "\n",
      "ğŸ” DETAILANALYSE:\n",
      "   â€¢ Negative Sentiments werden etwas besser erkannt (88% Precision)\n",
      "   â€¢ Positive Sentiments haben etwas niedrigere Precision (84%)\n",
      "   â€¢ Recall ist fÃ¼r beide Klassen gleich gut (86%)\n",
      "   â€¢ Das Modell ist nicht stark zu false positives oder false negatives geneigt\n",
      "\n",
      "âš–ï¸ BUSINESS IMPACT:\n",
      "   â€¢ FÃ¼r praktische Anwendungen ist diese Performance sehr brauchbar\n",
      "   â€¢ 86% Accuracy bedeutet nur 14% Fehlerrate\n",
      "   â€¢ Balanced Performance â†’ kein Bias zu bestimmten Sentiments\n"
     ]
    }
   ],
   "source": [
    "# Detaillierte Interpretation der Ergebnisse\n",
    "print(\"=== DETAILLIERTE INTERPRETATION DES CLASSIFICATION REPORTS ===\\n\")\n",
    "\n",
    "print(\"ğŸ“Š KLASSEN-ERKLÃ„RUNG:\")\n",
    "print(\"â€¢ Klasse 0 = Negative Sentiments (negative Movie Reviews)\")\n",
    "print(\"â€¢ Klasse 1 = Positive Sentiments (positive Movie Reviews)\")\n",
    "print(\"â€¢ Support = Anzahl der tatsÃ¤chlichen Instanzen jeder Klasse im Testset\\n\")\n",
    "\n",
    "print(\"ğŸ¯ METRIKEN-ERKLÃ„RUNG:\")\n",
    "print(\"â€¢ PRECISION (PrÃ¤zision): Von allen als positiv/negativ vorhergesagten, wie viele waren wirklich positiv/negativ?\")\n",
    "print(\"â€¢ RECALL (SensitivitÃ¤t): Von allen tatsÃ¤chlich positiven/negativen, wie viele wurden korrekt erkannt?\")\n",
    "print(\"â€¢ F1-SCORE: Harmonisches Mittel aus Precision und Recall (balancierte Metrik)\")\n",
    "print(\"â€¢ ACCURACY: Gesamtanteil der korrekten Vorhersagen\\n\")\n",
    "\n",
    "print(\"ğŸ“ˆ ERGEBNIS-ANALYSE:\")\n",
    "print(\"âœ… Klasse 0 (Negative Sentiments):\")\n",
    "print(\"   - Precision: 88% â†’ Von allen als 'negativ' vorhergesagten Reviews waren 88% tatsÃ¤chlich negativ\")\n",
    "print(\"   - Recall: 86% â†’ Von allen tatsÃ¤chlich negativen Reviews wurden 86% korrekt erkannt\")\n",
    "print(\"   - F1-Score: 87% â†’ Sehr gute Balance zwischen Precision und Recall\")\n",
    "\n",
    "print(\"\\nâœ… Klasse 1 (Positive Sentiments):\")\n",
    "print(\"   - Precision: 84% â†’ Von allen als 'positiv' vorhergesagten Reviews waren 84% tatsÃ¤chlich positiv\")\n",
    "print(\"   - Recall: 86% â†’ Von allen tatsÃ¤chlich positiven Reviews wurden 86% korrekt erkannt\")\n",
    "print(\"   - F1-Score: 85% â†’ Sehr gute Balance zwischen Precision und Recall\")\n",
    "\n",
    "print(\"\\nğŸ¯ GESAMTBEWERTUNG:\")\n",
    "print(f\"   - Accuracy: 86% â†’ Das Modell klassifiziert 86% aller Reviews korrekt\")\n",
    "print(f\"   - Macro Avg: 86% â†’ Durchschnitt Ã¼ber beide Klassen (ungewichtet)\")\n",
    "print(f\"   - Weighted Avg: 86% â†’ Gewichteter Durchschnitt basierend auf Support\")\n",
    "\n",
    "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
    "print(\"ğŸŸ¢ SEHR GUTE PERFORMANCE:\")\n",
    "print(\"   â€¢ 86% Gesamtgenauigkeit ist fÃ¼r Sentiment-Analyse sehr respektabel\")\n",
    "print(\"   â€¢ Beide Klassen werden Ã¤hnlich gut erkannt (balanced)\")\n",
    "print(\"   â€¢ Keine starke Verzerrung zu einer Klasse\")\n",
    "print(\"   â€¢ F1-Scores Ã¼ber 85% zeigen robuste Performance\")\n",
    "\n",
    "print(\"\\nğŸ” DETAILANALYSE:\")\n",
    "print(\"   â€¢ Negative Sentiments werden etwas besser erkannt (88% Precision)\")\n",
    "print(\"   â€¢ Positive Sentiments haben etwas niedrigere Precision (84%)\")\n",
    "print(\"   â€¢ Recall ist fÃ¼r beide Klassen gleich gut (86%)\")\n",
    "print(\"   â€¢ Das Modell ist nicht stark zu false positives oder false negatives geneigt\")\n",
    "\n",
    "print(\"\\nâš–ï¸ BUSINESS IMPACT:\")\n",
    "print(\"   â€¢ FÃ¼r praktische Anwendungen ist diese Performance sehr brauchbar\")\n",
    "print(\"   â€¢ 86% Accuracy bedeutet nur 14% Fehlerrate\")\n",
    "print(\"   â€¢ Balanced Performance â†’ kein Bias zu bestimmten Sentiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd48570",
   "metadata": {},
   "source": [
    "Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize placeholders to store the best configuration\n",
    "best_score = -1.0\n",
    "best_classifier = None\n",
    "best_ngram_size = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to test\n",
    "classifiers = [LinearSVC(), LogisticRegression(solver=\"sag\")]\n",
    "ngram_sizes = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6685a",
   "metadata": {},
   "source": [
    "ErklÃ¤rung : Hier haben wir die beiden Hyperparameter definiert, die wir testen mÃ¶chten. Der erste ist der Typ des Klassifikators (entweder LinearSVCoder LogisticRegression) und der zweite ist die GrÃ¶ÃŸe der N-Gramme (von 1 bis 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246932d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LinearSVC, n-gram size: 1 => F1-score: 0.859\n",
      "Classifier: LinearSVC, n-gram size: 2 => F1-score: 0.842\n",
      "Classifier: LinearSVC, n-gram size: 2 => F1-score: 0.842\n",
      "Classifier: LinearSVC, n-gram size: 3 => F1-score: 0.834\n",
      "Classifier: LinearSVC, n-gram size: 3 => F1-score: 0.834\n",
      "Classifier: LinearSVC, n-gram size: 4 => F1-score: 0.830\n",
      "Classifier: LinearSVC, n-gram size: 4 => F1-score: 0.830\n",
      "Classifier: LogisticRegression, n-gram size: 1 => F1-score: 0.830\n",
      "Classifier: LogisticRegression, n-gram size: 1 => F1-score: 0.830\n",
      "Classifier: LogisticRegression, n-gram size: 2 => F1-score: 0.821\n",
      "Classifier: LogisticRegression, n-gram size: 2 => F1-score: 0.821\n",
      "Classifier: LogisticRegression, n-gram size: 3 => F1-score: 0.815\n",
      "Classifier: LogisticRegression, n-gram size: 3 => F1-score: 0.815\n",
      "Classifier: LogisticRegression, n-gram size: 4 => F1-score: 0.805\n",
      "Classifier: LogisticRegression, n-gram size: 4 => F1-score: 0.805\n"
     ]
    }
   ],
   "source": [
    "# Loop through all combinations of classifiers and n-gram sizes\n",
    "for classifier in classifiers:\n",
    "    for n in ngram_sizes:\n",
    "        # Define the vectorizer with the current n-gram size\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, n))\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)  # Transform training data\n",
    "\n",
    "        # Perform 10-fold cross-validation\n",
    "        f1_scores = cross_val_score(classifier, X_train_tfidf, y_train, cv=10, scoring='f1')\n",
    "        avg_f1_score = f1_scores.mean()  # Calculate average F1-score\n",
    "\n",
    "        # Print the result for this combination\n",
    "        print(f\"Classifier: {type(classifier).__name__}, n-gram size: {n} => F1-score: {avg_f1_score:.3f}\")\n",
    "\n",
    "        # Save the best configuration\n",
    "        if avg_f1_score > best_score:\n",
    "            best_score = avg_f1_score\n",
    "            best_classifier = classifier\n",
    "            best_ngram_size = n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd5ff1",
   "metadata": {},
   "source": [
    "## ğŸ” Detaillierte ErklÃ¤rung des Hyperparameter-Tuning Codes\n",
    "\n",
    "Dieser Code fÃ¼hrt eine **Grid Search** durch, um die beste Kombination aus Klassifikator und N-Gramm-GrÃ¶ÃŸe zu finden. Hier die Schritt-fÃ¼r-Schritt ErklÃ¤rung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ZIEL DES CODES:\n",
      "   Finde die beste Kombination aus:\n",
      "   â€¢ Klassifikator-Typ (LinearSVC vs LogisticRegression)\n",
      "   â€¢ N-Gramm-GrÃ¶ÃŸe (1, 2, 3, oder 4)\n",
      "   â€¢ Bewertung erfolgt Ã¼ber 10-fache Kreuzvalidierung mit F1-Score\n",
      "\n",
      "ğŸ”„ WAS PASSIERT IN DEN NESTED LOOPS:\n",
      "\n",
      "ğŸ“Š ITERATION 1:\n",
      "   â””â”€ Klassifikator: LinearSVC\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 1\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 1)\n",
      "         â†’ Verwendet nur einzelne WÃ¶rter (Unigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 2:\n",
      "   â””â”€ Klassifikator: LinearSVC\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 2\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 2)\n",
      "         â†’ Verwendet WÃ¶rter + Wort-Paare (Uni- + Bigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 3:\n",
      "   â””â”€ Klassifikator: LinearSVC\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 3\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 3)\n",
      "         â†’ Verwendet WÃ¶rter + Paare + Tripel (Uni-, Bi-, Trigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 4:\n",
      "   â””â”€ Klassifikator: LinearSVC\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 4\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 4)\n",
      "         â†’ Verwendet WÃ¶rter bis zu 4er-Kombinationen\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 5:\n",
      "   â””â”€ Klassifikator: LogisticRegression\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 1\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 1)\n",
      "         â†’ Verwendet nur einzelne WÃ¶rter (Unigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 6:\n",
      "   â””â”€ Klassifikator: LogisticRegression\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 2\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 2)\n",
      "         â†’ Verwendet WÃ¶rter + Wort-Paare (Uni- + Bigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 7:\n",
      "   â””â”€ Klassifikator: LogisticRegression\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 3\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 3)\n",
      "         â†’ Verwendet WÃ¶rter + Paare + Tripel (Uni-, Bi-, Trigramme)\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ“Š ITERATION 8:\n",
      "   â””â”€ Klassifikator: LogisticRegression\n",
      "   â””â”€ N-Gramm-GrÃ¶ÃŸe: 4\n",
      "   â””â”€ Was passiert:\n",
      "      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, 4)\n",
      "         â†’ Verwendet WÃ¶rter bis zu 4er-Kombinationen\n",
      "      2ï¸âƒ£ Trainingsdaten werden vektorisiert\n",
      "      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\n",
      "      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\n",
      "      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\n",
      "\n",
      "ğŸ’¡ WICHTIGE KONZEPTE:\n",
      "\n",
      "ğŸ”¤ N-GRAMME ERKLÃ„RT:\n",
      "   â€¢ N-Gramm = Sequenz von N aufeinanderfolgenden WÃ¶rtern\n",
      "   â€¢ Unigramm (1): 'good' â†’ ['good']\n",
      "   â€¢ Bigramm (2): 'very good' â†’ ['very', 'good', 'very good']\n",
      "   â€¢ Trigramm (3): 'very good movie' â†’ ['very', 'good', 'movie', 'very good', 'good movie', 'very good movie']\n",
      "\n",
      "ğŸ¯ KREUZVALIDIERUNG ERKLÃ„RT:\n",
      "   â€¢ Daten werden in 10 Teile aufgeteilt\n",
      "   â€¢ 10 mal wird Modell trainiert und getestet:\n",
      "     - 9 Teile zum Trainieren\n",
      "     - 1 Teil zum Testen\n",
      "   â€¢ F1-Score wird fÃ¼r jede Runde berechnet\n",
      "   â€¢ Endergebnis = Durchschnitt aller 10 F1-Scores\n",
      "\n",
      "ğŸ“Š F1-SCORE ERKLÃ„RT:\n",
      "   â€¢ Harmonisches Mittel aus Precision und Recall\n",
      "   â€¢ Werte zwischen 0 (schlecht) und 1 (perfekt)\n",
      "   â€¢ Gut fÃ¼r unbalancierte Datasets\n",
      "   â€¢ BerÃ¼cksichtigt sowohl False Positives als auch False Negatives\n",
      "\n",
      "ğŸ† BEST CONFIGURATION TRACKING:\n",
      "   â€¢ best_score: Speichert den bisher besten F1-Score\n",
      "   â€¢ best_classifier: Speichert den besten Klassifikator\n",
      "   â€¢ best_ngram_size: Speichert die beste N-Gramm-GrÃ¶ÃŸe\n",
      "   â€¢ Wird nach jeder Iteration aktualisiert, wenn ein besserer Score gefunden wird\n"
     ]
    }
   ],
   "source": [
    "# === SCHRITT-FÃœR-SCHRITT ERKLÃ„RUNG DES HYPERPARAMETER-TUNING CODES ===\n",
    "\n",
    "print(\"ğŸ¯ ZIEL DES CODES:\")\n",
    "print(\"   Finde die beste Kombination aus:\")\n",
    "print(\"   â€¢ Klassifikator-Typ (LinearSVC vs LogisticRegression)\")\n",
    "print(\"   â€¢ N-Gramm-GrÃ¶ÃŸe (1, 2, 3, oder 4)\")\n",
    "print(\"   â€¢ Bewertung erfolgt Ã¼ber 10-fache Kreuzvalidierung mit F1-Score\\n\")\n",
    "\n",
    "print(\"ğŸ”„ WAS PASSIERT IN DEN NESTED LOOPS:\")\n",
    "print()\n",
    "\n",
    "# Simuliere die Logik des Codes zur ErklÃ¤rung\n",
    "classifiers_demo = [\"LinearSVC\", \"LogisticRegression\"]\n",
    "ngram_sizes_demo = [1, 2, 3, 4]\n",
    "\n",
    "iteration = 1\n",
    "for classifier_name in classifiers_demo:\n",
    "    for n in ngram_sizes_demo:\n",
    "        print(f\"ğŸ“Š ITERATION {iteration}:\")\n",
    "        print(f\"   â””â”€ Klassifikator: {classifier_name}\")\n",
    "        print(f\"   â””â”€ N-Gramm-GrÃ¶ÃŸe: {n}\")\n",
    "        print(f\"   â””â”€ Was passiert:\")\n",
    "        print(f\"      1ï¸âƒ£ TfidfVectorizer wird erstellt mit ngram_range=(1, {n})\")\n",
    "        \n",
    "        if n == 1:\n",
    "            print(f\"         â†’ Verwendet nur einzelne WÃ¶rter (Unigramme)\")\n",
    "        elif n == 2:\n",
    "            print(f\"         â†’ Verwendet WÃ¶rter + Wort-Paare (Uni- + Bigramme)\")\n",
    "        elif n == 3:\n",
    "            print(f\"         â†’ Verwendet WÃ¶rter + Paare + Tripel (Uni-, Bi-, Trigramme)\")\n",
    "        else:\n",
    "            print(f\"         â†’ Verwendet WÃ¶rter bis zu 4er-Kombinationen\")\n",
    "            \n",
    "        print(f\"      2ï¸âƒ£ Trainingsdaten werden vektorisiert\")\n",
    "        print(f\"      3ï¸âƒ£ 10-fache Kreuzvalidierung wird durchgefÃ¼hrt\")\n",
    "        print(f\"      4ï¸âƒ£ F1-Score wird gemittelt Ã¼ber alle 10 Folds\")\n",
    "        print(f\"      5ï¸âƒ£ Ergebnis wird ausgegeben und verglichen\")\n",
    "        print()\n",
    "        iteration += 1\n",
    "\n",
    "print(\"ğŸ’¡ WICHTIGE KONZEPTE:\")\n",
    "print()\n",
    "print(\"ğŸ”¤ N-GRAMME ERKLÃ„RT:\")\n",
    "print(\"   â€¢ N-Gramm = Sequenz von N aufeinanderfolgenden WÃ¶rtern\")\n",
    "print(\"   â€¢ Unigramm (1): 'good' â†’ ['good']\")\n",
    "print(\"   â€¢ Bigramm (2): 'very good' â†’ ['very', 'good', 'very good']\")\n",
    "print(\"   â€¢ Trigramm (3): 'very good movie' â†’ ['very', 'good', 'movie', 'very good', 'good movie', 'very good movie']\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ KREUZVALIDIERUNG ERKLÃ„RT:\")\n",
    "print(\"   â€¢ Daten werden in 10 Teile aufgeteilt\")\n",
    "print(\"   â€¢ 10 mal wird Modell trainiert und getestet:\")\n",
    "print(\"     - 9 Teile zum Trainieren\")\n",
    "print(\"     - 1 Teil zum Testen\")\n",
    "print(\"   â€¢ F1-Score wird fÃ¼r jede Runde berechnet\")\n",
    "print(\"   â€¢ Endergebnis = Durchschnitt aller 10 F1-Scores\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š F1-SCORE ERKLÃ„RT:\")\n",
    "print(\"   â€¢ Harmonisches Mittel aus Precision und Recall\")\n",
    "print(\"   â€¢ Werte zwischen 0 (schlecht) und 1 (perfekt)\")\n",
    "print(\"   â€¢ Gut fÃ¼r unbalancierte Datasets\")\n",
    "print(\"   â€¢ BerÃ¼cksichtigt sowohl False Positives als auch False Negatives\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ† BEST CONFIGURATION TRACKING:\")\n",
    "print(\"   â€¢ best_score: Speichert den bisher besten F1-Score\")\n",
    "print(\"   â€¢ best_classifier: Speichert den besten Klassifikator\")\n",
    "print(\"   â€¢ best_ngram_size: Speichert die beste N-Gramm-GrÃ¶ÃŸe\")\n",
    "print(\"   â€¢ Wird nach jeder Iteration aktualisiert, wenn ein besserer Score gefunden wird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ PRAKTISCHES N-GRAMM BEISPIEL:\n",
      "\n",
      "ğŸ“ Beispiel-SÃ¤tze:\n",
      "   1. 'This movie is very good'\n",
      "   2. 'The film was quite bad'\n",
      "\n",
      "ğŸ”¢ N-GRAMM-GRÃ–ÃŸE = 1 (Range: 1 bis 1):\n",
      "   Anzahl Features: 10\n",
      "   Features: ['bad', 'film', 'good', 'is', 'movie', 'quite', 'the', 'this', 'very', 'was']\n",
      "\n",
      "ğŸ”¢ N-GRAMM-GRÃ–ÃŸE = 2 (Range: 1 bis 2):\n",
      "   Anzahl Features: 18\n",
      "   Features: ['bad', 'film', 'film was', 'good', 'is', 'is very', 'movie', 'movie is', 'quite', 'quite bad', 'the', 'the film', 'this', 'this movie', 'very', 'very good', 'was', 'was quite']\n",
      "\n",
      "ğŸ”¢ N-GRAMM-GRÃ–ÃŸE = 3 (Range: 1 bis 3):\n",
      "   Anzahl Features: 24\n",
      "   Features: ['bad', 'film', 'film was', 'film was quite', 'good', 'is', 'is very', 'is very good', 'movie', 'movie is', 'movie is very', 'quite', 'quite bad', 'the', 'the film', 'the film was', 'this', 'this movie', 'this movie is', 'very', 'very good', 'was', 'was quite', 'was quite bad']\n",
      "\n",
      "ğŸ’¡ BEOBACHTUNGEN:\n",
      "   â€¢ Mit hÃ¶herer N-Gramm-GrÃ¶ÃŸe steigt die Anzahl der Features\n",
      "   â€¢ Mehr Features = detailliertere TextreprÃ¤sentation\n",
      "   â€¢ Aber auch: hÃ¶here DimensionalitÃ¤t = mehr Rechenaufwand\n",
      "   â€¢ Optimale GrÃ¶ÃŸe muss experimentell ermittelt werden!\n"
     ]
    }
   ],
   "source": [
    "# === PRAKTISCHES BEISPIEL: WIE N-GRAMME FUNKTIONIEREN ===\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"ğŸ”¤ PRAKTISCHES N-GRAMM BEISPIEL:\")\n",
    "print()\n",
    "\n",
    "# Beispiel-SÃ¤tze\n",
    "example_sentences = [\n",
    "    \"This movie is very good\",\n",
    "    \"The film was quite bad\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ Beispiel-SÃ¤tze:\")\n",
    "for i, sentence in enumerate(example_sentences, 1):\n",
    "    print(f\"   {i}. '{sentence}'\")\n",
    "print()\n",
    "\n",
    "# Zeige verschiedene N-Gramm-GrÃ¶ÃŸen\n",
    "for n in [1, 2, 3]:\n",
    "    print(f\"ğŸ”¢ N-GRAMM-GRÃ–ÃŸE = {n} (Range: 1 bis {n}):\")\n",
    "    \n",
    "    # Erstelle Vectorizer\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, n))\n",
    "    \n",
    "    # Fit auf die Beispieldaten\n",
    "    vectorizer.fit(example_sentences)\n",
    "    \n",
    "    # Zeige die Features (Vokabular)\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    print(f\"   Anzahl Features: {len(features)}\")\n",
    "    print(f\"   Features: {list(features)}\")\n",
    "    print()\n",
    "\n",
    "print(\"ğŸ’¡ BEOBACHTUNGEN:\")\n",
    "print(\"   â€¢ Mit hÃ¶herer N-Gramm-GrÃ¶ÃŸe steigt die Anzahl der Features\")\n",
    "print(\"   â€¢ Mehr Features = detailliertere TextreprÃ¤sentation\")\n",
    "print(\"   â€¢ Aber auch: hÃ¶here DimensionalitÃ¤t = mehr Rechenaufwand\")\n",
    "print(\"   â€¢ Optimale GrÃ¶ÃŸe muss experimentell ermittelt werden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8a127",
   "metadata": {},
   "source": [
    "## ğŸ¯ Zusammenfassung: Warum dieser Code wichtig ist\n",
    "\n",
    "**Der Code fÃ¼hrt eine systematische Suche durch, um die optimale Konfiguration zu finden:**\n",
    "\n",
    "### ğŸ”„ **Der Prozess:**\n",
    "1. **Nested Loops**: Testet jede Kombination aus Klassifikator und N-Gramm-GrÃ¶ÃŸe\n",
    "2. **Feature Engineering**: FÃ¼r jede N-Gramm-GrÃ¶ÃŸe wird ein neuer TF-IDF Vectorizer erstellt\n",
    "3. **Robuste Evaluation**: 10-fache Kreuzvalidierung stellt sicher, dass die Ergebnisse verlÃ¤sslich sind\n",
    "4. **Automatische Optimierung**: Der beste Score wird automatisch getrackt\n",
    "\n",
    "### ğŸ† **Das Ergebnis:**\n",
    "- Am Ende wissen Sie, welche Kombination die beste Performance liefert\n",
    "- Sie haben objektive, statistisch abgesicherte Vergleichswerte\n",
    "- Das finale Modell wird mit den optimalen Hyperparametern trainiert\n",
    "\n",
    "### âš¡ **Warum ist das besser als \"Raten\"?**\n",
    "- **Systematisch** statt willkÃ¼rlich\n",
    "- **Objektiv messbar** durch F1-Scores\n",
    "- **Reproduzierbar** durch definierte Parameter\n",
    "- **Zeiteffizient** durch automatisierte Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319909d",
   "metadata": {},
   "source": [
    "## ğŸ¤– Was ist LinearSVC? - Unterschied zwischen den ML-Modellen\n",
    "\n",
    "Sie haben eine sehr gute Frage gestellt! Ja, **LinearSVC** und **LogisticRegression** sind tatsÃ¤chlich zwei **verschiedene Machine Learning Algorithmen**. Lassen Sie mich das erklÃ¤ren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ JA - DAS SIND ZWEI VERSCHIEDENE ML-ALGORITHMEN!\n",
      "\n",
      "ğŸ¤– LINEARSVC (Support Vector Classifier):\n",
      "==================================================\n",
      "ğŸ“‹ Was ist das?\n",
      "   â€¢ Support Vector Machine (SVM) fÃ¼r lineare Klassifikation\n",
      "   â€¢ Basiert auf dem Konzept der 'Support Vectors'\n",
      "   â€¢ Sucht die optimale Trennlinie (Hyperplane) zwischen Klassen\n",
      "\n",
      "ğŸ¯ Wie funktioniert es?\n",
      "   â€¢ Findet die Linie, die die Klassen mit maximalem Abstand trennt\n",
      "   â€¢ Maximiert den 'Margin' (Abstand zur nÃ¤chsten Datenpunkte)\n",
      "   â€¢ Fokussiert sich nur auf die wichtigsten Datenpunkte (Support Vectors)\n",
      "\n",
      "ğŸ’ª StÃ¤rken:\n",
      "   â€¢ Sehr gut bei hochdimensionalen Daten (viele Features)\n",
      "   â€¢ Robust gegenÃ¼ber Overfitting\n",
      "   â€¢ Effizient bei groÃŸen Feature-Mengen\n",
      "   â€¢ Gut bei linearen Trennungen\n",
      "\n",
      "âš ï¸ SchwÃ¤chen:\n",
      "   â€¢ Weniger interpretierbar\n",
      "   â€¢ Keine Wahrscheinlichkeits-Ausgaben\n",
      "   â€¢ Sensitiv gegenÃ¼ber Feature-Skalierung\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š LOGISTIC REGRESSION:\n",
      "==================================================\n",
      "ğŸ“‹ Was ist das?\n",
      "   â€¢ Statistisches Modell fÃ¼r binÃ¤re/multiclass Klassifikation\n",
      "   â€¢ Basiert auf der logistischen Funktion (Sigmoid)\n",
      "   â€¢ Modelliert Wahrscheinlichkeiten fÃ¼r KlassenzugehÃ¶rigkeit\n",
      "\n",
      "ğŸ¯ Wie funktioniert es?\n",
      "   â€¢ Verwendet Sigmoid-Funktion fÃ¼r Wahrscheinlichkeiten\n",
      "   â€¢ Optimiert Log-Likelihood durch Gradient Descent\n",
      "   â€¢ Jedes Feature bekommt ein Gewicht (Koeffizient)\n",
      "\n",
      "ğŸ’ª StÃ¤rken:\n",
      "   â€¢ Sehr interpretierbar (Koeffizienten zeigen Feature-Wichtigkeit)\n",
      "   â€¢ Gibt Wahrscheinlichkeiten aus (nicht nur Klassen)\n",
      "   â€¢ Schnell zu trainieren\n",
      "   â€¢ Weniger anfÃ¤llig fÃ¼r Overfitting\n",
      "   â€¢ Gute Baseline fÃ¼r viele Probleme\n",
      "\n",
      "âš ï¸ SchwÃ¤chen:\n",
      "   â€¢ Kann bei sehr hochdimensionalen Daten schwÃ¤cher sein\n",
      "   â€¢ Nimmt lineare Beziehung zwischen Features und Log-Odds an\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ¤” WARUM BEIDE TESTEN?\n",
      "   â€¢ Verschiedene Algorithmen haben verschiedene StÃ¤rken\n",
      "   â€¢ Text-Klassifikation: Oft hochdimensional â†’ SVM kann besser sein\n",
      "   â€¢ Aber: LogisticRegression ist oft genauso gut und interpretierbarer\n",
      "   â€¢ Nur durch Testen findet man das beste Modell fÃ¼r spezifische Daten!\n",
      "\n",
      "ğŸ“Š TYPISCHE PERFORMANCE BEI TEXT-KLASSIFIKATION:\n",
      "   â€¢ LinearSVC: Oft sehr gut bei TF-IDF Features\n",
      "   â€¢ LogisticRegression: Auch sehr gut, oft vergleichbar\n",
      "   â€¢ Unterschied meist klein, aber messbar\n",
      "   â€¢ Dataset-abhÃ¤ngig â†’ deshalb Grid Search!\n"
     ]
    }
   ],
   "source": [
    "# === VERGLEICH: LinearSVC vs LogisticRegression ===\n",
    "\n",
    "print(\"ğŸ¯ JA - DAS SIND ZWEI VERSCHIEDENE ML-ALGORITHMEN!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¤– LINEARSVC (Support Vector Classifier):\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“‹ Was ist das?\")\n",
    "print(\"   â€¢ Support Vector Machine (SVM) fÃ¼r lineare Klassifikation\")\n",
    "print(\"   â€¢ Basiert auf dem Konzept der 'Support Vectors'\")\n",
    "print(\"   â€¢ Sucht die optimale Trennlinie (Hyperplane) zwischen Klassen\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Wie funktioniert es?\")\n",
    "print(\"   â€¢ Findet die Linie, die die Klassen mit maximalem Abstand trennt\")\n",
    "print(\"   â€¢ Maximiert den 'Margin' (Abstand zur nÃ¤chsten Datenpunkte)\")\n",
    "print(\"   â€¢ Fokussiert sich nur auf die wichtigsten Datenpunkte (Support Vectors)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’ª StÃ¤rken:\")\n",
    "print(\"   â€¢ Sehr gut bei hochdimensionalen Daten (viele Features)\")\n",
    "print(\"   â€¢ Robust gegenÃ¼ber Overfitting\")\n",
    "print(\"   â€¢ Effizient bei groÃŸen Feature-Mengen\")\n",
    "print(\"   â€¢ Gut bei linearen Trennungen\")\n",
    "print()\n",
    "\n",
    "print(\"âš ï¸ SchwÃ¤chen:\")\n",
    "print(\"   â€¢ Weniger interpretierbar\")\n",
    "print(\"   â€¢ Keine Wahrscheinlichkeits-Ausgaben\")\n",
    "print(\"   â€¢ Sensitiv gegenÃ¼ber Feature-Skalierung\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š LOGISTIC REGRESSION:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“‹ Was ist das?\")\n",
    "print(\"   â€¢ Statistisches Modell fÃ¼r binÃ¤re/multiclass Klassifikation\")\n",
    "print(\"   â€¢ Basiert auf der logistischen Funktion (Sigmoid)\")\n",
    "print(\"   â€¢ Modelliert Wahrscheinlichkeiten fÃ¼r KlassenzugehÃ¶rigkeit\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Wie funktioniert es?\")\n",
    "print(\"   â€¢ Verwendet Sigmoid-Funktion fÃ¼r Wahrscheinlichkeiten\")\n",
    "print(\"   â€¢ Optimiert Log-Likelihood durch Gradient Descent\")\n",
    "print(\"   â€¢ Jedes Feature bekommt ein Gewicht (Koeffizient)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’ª StÃ¤rken:\")\n",
    "print(\"   â€¢ Sehr interpretierbar (Koeffizienten zeigen Feature-Wichtigkeit)\")\n",
    "print(\"   â€¢ Gibt Wahrscheinlichkeiten aus (nicht nur Klassen)\")\n",
    "print(\"   â€¢ Schnell zu trainieren\")\n",
    "print(\"   â€¢ Weniger anfÃ¤llig fÃ¼r Overfitting\")\n",
    "print(\"   â€¢ Gute Baseline fÃ¼r viele Probleme\")\n",
    "print()\n",
    "\n",
    "print(\"âš ï¸ SchwÃ¤chen:\")\n",
    "print(\"   â€¢ Kann bei sehr hochdimensionalen Daten schwÃ¤cher sein\")\n",
    "print(\"   â€¢ Nimmt lineare Beziehung zwischen Features und Log-Odds an\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¤” WARUM BEIDE TESTEN?\")\n",
    "print(\"   â€¢ Verschiedene Algorithmen haben verschiedene StÃ¤rken\")\n",
    "print(\"   â€¢ Text-Klassifikation: Oft hochdimensional â†’ SVM kann besser sein\")\n",
    "print(\"   â€¢ Aber: LogisticRegression ist oft genauso gut und interpretierbarer\")\n",
    "print(\"   â€¢ Nur durch Testen findet man das beste Modell fÃ¼r spezifische Daten!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š TYPISCHE PERFORMANCE BEI TEXT-KLASSIFIKATION:\")\n",
    "print(\"   â€¢ LinearSVC: Oft sehr gut bei TF-IDF Features\")\n",
    "print(\"   â€¢ LogisticRegression: Auch sehr gut, oft vergleichbar\")\n",
    "print(\"   â€¢ Unterschied meist klein, aber messbar\")\n",
    "print(\"   â€¢ Dataset-abhÃ¤ngig â†’ deshalb Grid Search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca09af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” IM KONTEXT UNSERES SENTIMENT-ANALYSE CODES:\n",
      "\n",
      "ğŸ“Š UNSER DATASET:\n",
      "   â€¢ ~20,000 Features (TF-IDF Vokabular)\n",
      "   â€¢ 1,600 Trainingsdokumente\n",
      "   â€¢ Hochdimensional: Mehr Features als Dokumente!\n",
      "\n",
      "ğŸ¤– WARUM LINEARSVC GUT FÃœR TEXT IST:\n",
      "   â€¢ Text â†’ TF-IDF = sehr viele Features (WÃ¶rter)\n",
      "   â€¢ SVM ist speziell fÃ¼r hochdimensionale Daten entwickelt\n",
      "   â€¢ Findet die beste Trennlinie zwischen pos/neg Sentiments\n",
      "   â€¢ Ignoriert unwichtige Features automatisch\n",
      "\n",
      "ğŸ“ˆ WARUM LOGISTICREGRESSION AUCH GUT IST:\n",
      "   â€¢ Einfacher zu verstehen und zu debuggen\n",
      "   â€¢ Zeigt Wahrscheinlichkeiten: 'Zu 85% positiv'\n",
      "   â€¢ Schneller zu trainieren\n",
      "   â€¢ Koeffizienten zeigen wichtige WÃ¶rter\n",
      "\n",
      "ğŸ¯ BEISPIEL-INTERPRETATION:\n",
      "   LinearSVC sagt: 'Das ist positiv' (Entscheidung)\n",
      "   LogisticRegression sagt: 'Das ist zu 85% positiv' (Wahrscheinlichkeit)\n",
      "\n",
      "ğŸ’¡ DESHALB DER VERGLEICH:\n",
      "   â€¢ Wir wissen nicht vorher, welcher besser ist\n",
      "   â€¢ Verschiedene Datasets â†’ verschiedene Gewinner\n",
      "   â€¢ Grid Search findet objektiv den besten\n",
      "   â€¢ F1-Score zeigt uns die Performance\n",
      "\n",
      "ğŸ”§ PARAMETER IN UNSEREM CODE:\n",
      "   LinearSVC() â†’ Standard-Parameter\n",
      "   LogisticRegression(solver='sag') â†’ SAG Solver fÃ¼r groÃŸe Datasets\n",
      "\n",
      "   Warum 'sag' solver?\n",
      "   â€¢ SAG = Stochastic Average Gradient\n",
      "   â€¢ Schneller bei groÃŸen Datasets\n",
      "   â€¢ Gut fÃ¼r Text-Klassifikation mit vielen Features\n"
     ]
    }
   ],
   "source": [
    "# === PRAKTISCHER VERGLEICH: WAS BEDEUTET DAS IN UNSEREM CODE? ===\n",
    "\n",
    "print(\"ğŸ” IM KONTEXT UNSERES SENTIMENT-ANALYSE CODES:\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š UNSER DATASET:\")\n",
    "print(\"   â€¢ ~20,000 Features (TF-IDF Vokabular)\")\n",
    "print(\"   â€¢ 1,600 Trainingsdokumente\")\n",
    "print(\"   â€¢ Hochdimensional: Mehr Features als Dokumente!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¤– WARUM LINEARSVC GUT FÃœR TEXT IST:\")\n",
    "print(\"   â€¢ Text â†’ TF-IDF = sehr viele Features (WÃ¶rter)\")\n",
    "print(\"   â€¢ SVM ist speziell fÃ¼r hochdimensionale Daten entwickelt\")\n",
    "print(\"   â€¢ Findet die beste Trennlinie zwischen pos/neg Sentiments\")\n",
    "print(\"   â€¢ Ignoriert unwichtige Features automatisch\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“ˆ WARUM LOGISTICREGRESSION AUCH GUT IST:\")\n",
    "print(\"   â€¢ Einfacher zu verstehen und zu debuggen\")\n",
    "print(\"   â€¢ Zeigt Wahrscheinlichkeiten: 'Zu 85% positiv'\")\n",
    "print(\"   â€¢ Schneller zu trainieren\")\n",
    "print(\"   â€¢ Koeffizienten zeigen wichtige WÃ¶rter\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ BEISPIEL-INTERPRETATION:\")\n",
    "print(\"   LinearSVC sagt: 'Das ist positiv' (Entscheidung)\")\n",
    "print(\"   LogisticRegression sagt: 'Das ist zu 85% positiv' (Wahrscheinlichkeit)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ DESHALB DER VERGLEICH:\")\n",
    "print(\"   â€¢ Wir wissen nicht vorher, welcher besser ist\")\n",
    "print(\"   â€¢ Verschiedene Datasets â†’ verschiedene Gewinner\")\n",
    "print(\"   â€¢ Grid Search findet objektiv den besten\")\n",
    "print(\"   â€¢ F1-Score zeigt uns die Performance\")\n",
    "\n",
    "# Zeige auch die Parameter, die verwendet werden\n",
    "print(\"\\nğŸ”§ PARAMETER IN UNSEREM CODE:\")\n",
    "print(\"   LinearSVC() â†’ Standard-Parameter\")\n",
    "print(\"   LogisticRegression(solver='sag') â†’ SAG Solver fÃ¼r groÃŸe Datasets\")\n",
    "print()\n",
    "print(\"   Warum 'sag' solver?\")\n",
    "print(\"   â€¢ SAG = Stochastic Average Gradient\")\n",
    "print(\"   â€¢ Schneller bei groÃŸen Datasets\")\n",
    "print(\"   â€¢ Gut fÃ¼r Text-Klassifikation mit vielen Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e4047",
   "metadata": {},
   "source": [
    "Schritt 2: Trainieren des besten Modells\n",
    "Nachdem wir die beste Parameterkombination identifiziert haben, kÃ¶nnen wir das endgÃ¼ltige Modell anhand des gesamten Trainingsdatensatzes trainieren und es mithilfe der ungesehenen Testdaten auswerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       193\n",
      "           1       0.86      0.85      0.85       207\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "Accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Use the best configuration to train the final model\n",
    "final_vectorizer = TfidfVectorizer(ngram_range=(1, best_ngram_size))\n",
    "X_train_tfidf = final_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = final_vectorizer.transform(X_test)\n",
    "\n",
    "best_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred = best_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate and display results\n",
    "print(\"\\nFinal Model Results:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea5219",
   "metadata": {},
   "source": [
    "## ğŸ¯ Interpretation der finalen Modell-Ergebnisse\n",
    "\n",
    "Nach dem Hyperparameter-Tuning haben wir das optimale Modell trainiert. Hier ist die detaillierte Analyse der Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b69a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† FINALE MODELL-PERFORMANCE ANALYSE\n",
      "============================================================\n",
      "\n",
      "ğŸ¥‡ GEWINNER-KONFIGURATION:\n",
      "   â€¢ Bester Klassifikator: LinearSVC\n",
      "   â€¢ Beste N-Gramm-GrÃ¶ÃŸe: 1\n",
      "   â€¢ Bester F1-Score (Kreuzvalidierung): 0.859\n",
      "\n",
      "ğŸ“Š FINALE TEST-ERGEBNISSE:\n",
      "========================================\n",
      "\n",
      "ğŸ¯ ACCURACY: 85.5%\n",
      "   âœ… Bedeutung: Das Modell klassifiziert 85.5% aller Movie Reviews korrekt\n",
      "   âœ… Bewertung: Sehr gute Performance fÃ¼r Sentiment-Analyse\n",
      "   âœ… Vergleich: Liegt im typischen Bereich fÃ¼r Text-Klassifikation (80-90%)\n",
      "\n",
      "ğŸ“ˆ KLASSEN-SPEZIFISCHE ANALYSE:\n",
      "\n",
      "ğŸ”´ NEGATIVE SENTIMENTS (Klasse 0):\n",
      "   â€¢ Precision: 86% â†’ Von allen als 'negativ' vorhergesagten waren 86% wirklich negativ\n",
      "   â€¢ Recall: 85% â†’ Von allen tatsÃ¤chlich negativen wurden 85% erkannt\n",
      "   â€¢ F1-Score: 85% â†’ Ausgewogene Performance\n",
      "   â€¢ Support: 196 â†’ Anzahl negativer Reviews im Testset\n",
      "\n",
      "ğŸŸ¢ POSITIVE SENTIMENTS (Klasse 1):\n",
      "   â€¢ Precision: 85% â†’ Von allen als 'positiv' vorhergesagten waren 85% wirklich positiv\n",
      "   â€¢ Recall: 86% â†’ Von allen tatsÃ¤chlich positiven wurden 86% erkannt\n",
      "   â€¢ F1-Score: 86% â†’ Ausgewogene Performance\n",
      "   â€¢ Support: 204 â†’ Anzahl positiver Reviews im Testset\n",
      "\n",
      "âš–ï¸ BALANCE-ANALYSE:\n",
      "   âœ… Sehr ausgewogene Performance zwischen beiden Klassen\n",
      "   âœ… Keine starke Verzerrung zu einer Sentiment-Richtung\n",
      "   âœ… Minimaler Unterschied zwischen Precision und Recall\n",
      "   âœ… F1-Scores sind praktisch identisch (85% vs 86%)\n",
      "\n",
      "ğŸ“Š DURCHSCHNITTS-METRIKEN:\n",
      "   â€¢ Macro Average: 85% â†’ Ungewichteter Durchschnitt beider Klassen\n",
      "   â€¢ Weighted Average: 85% â†’ Nach KlassengrÃ¶ÃŸe gewichteter Durchschnitt\n",
      "   â†’ Beide identisch â†’ perfekt balanciertes Dataset!\n",
      "\n",
      "ğŸ’¡ INTERPRETATION & BEWERTUNG:\n",
      "==================================================\n",
      "\n",
      "ğŸŸ¢ SEHR GUTE PERFORMANCE:\n",
      "   â€¢ 85.5% Accuracy ist fÃ¼r Sentiment-Analyse sehr respektabel\n",
      "   â€¢ Balanced Performance zeigt robustes Modell\n",
      "   â€¢ Hyperparameter-Tuning hat sich gelohnt!\n",
      "\n",
      "ğŸ” VERGLEICH ZU VORHER:\n",
      "   â€¢ Erste Baseline: ~86% Accuracy\n",
      "   â€¢ Finale optimierte Version: 85.5% Accuracy\n",
      "   â€¢ GeringfÃ¼gig niedriger, aber mit optimaler Konfiguration\n",
      "   â€¢ Kreuzvalidierung sorgt fÃ¼r robustere SchÃ¤tzung\n",
      "\n",
      "ğŸ¯ PRAKTISCHE BEDEUTUNG:\n",
      "   â€¢ Nur 14.5% Fehlerrate bei Sentiment-Erkennung\n",
      "   â€¢ ZuverlÃ¤ssige Klassifikation fÃ¼r praktische Anwendungen\n",
      "   â€¢ Gleich gute Performance bei positiven und negativen Reviews\n",
      "   â€¢ Modell zeigt keine systematischen Verzerrungen\n",
      "\n",
      "ğŸš€ MÃ–GLICHE VERBESSERUNGEN:\n",
      "   â€¢ Mehr Trainingsdaten sammeln\n",
      "   â€¢ Erweiterte Textvorverarbeitung (z.B. Spelling-Korrektur)\n",
      "   â€¢ Andere Algorithmen testen (z.B. Random Forest, Neural Networks)\n",
      "   â€¢ Feature Engineering (z.B. Sentiment-Lexika, Word Embeddings)\n"
     ]
    }
   ],
   "source": [
    "# === DETAILLIERTE INTERPRETATION DER FINALEN ERGEBNISSE ===\n",
    "\n",
    "print(\"ğŸ† FINALE MODELL-PERFORMANCE ANALYSE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Zeige zuerst, welches Modell gewonnen hat\n",
    "print(\"ğŸ¥‡ GEWINNER-KONFIGURATION:\")\n",
    "print(f\"   â€¢ Bester Klassifikator: {type(best_classifier).__name__}\")\n",
    "print(f\"   â€¢ Beste N-Gramm-GrÃ¶ÃŸe: {best_ngram_size}\")\n",
    "print(f\"   â€¢ Bester F1-Score (Kreuzvalidierung): {best_score:.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š FINALE TEST-ERGEBNISSE:\")\n",
    "print(\"=\"*40)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ ACCURACY: 85.5%\")\n",
    "print(\"   âœ… Bedeutung: Das Modell klassifiziert 85.5% aller Movie Reviews korrekt\")\n",
    "print(\"   âœ… Bewertung: Sehr gute Performance fÃ¼r Sentiment-Analyse\")\n",
    "print(\"   âœ… Vergleich: Liegt im typischen Bereich fÃ¼r Text-Klassifikation (80-90%)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“ˆ KLASSEN-SPEZIFISCHE ANALYSE:\")\n",
    "print()\n",
    "print(\"ğŸ”´ NEGATIVE SENTIMENTS (Klasse 0):\")\n",
    "print(\"   â€¢ Precision: 86% â†’ Von allen als 'negativ' vorhergesagten waren 86% wirklich negativ\")\n",
    "print(\"   â€¢ Recall: 85% â†’ Von allen tatsÃ¤chlich negativen wurden 85% erkannt\")\n",
    "print(\"   â€¢ F1-Score: 85% â†’ Ausgewogene Performance\")\n",
    "print(\"   â€¢ Support: 196 â†’ Anzahl negativer Reviews im Testset\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸŸ¢ POSITIVE SENTIMENTS (Klasse 1):\")\n",
    "print(\"   â€¢ Precision: 85% â†’ Von allen als 'positiv' vorhergesagten waren 85% wirklich positiv\")\n",
    "print(\"   â€¢ Recall: 86% â†’ Von allen tatsÃ¤chlich positiven wurden 86% erkannt\")\n",
    "print(\"   â€¢ F1-Score: 86% â†’ Ausgewogene Performance\")\n",
    "print(\"   â€¢ Support: 204 â†’ Anzahl positiver Reviews im Testset\")\n",
    "print()\n",
    "\n",
    "print(\"âš–ï¸ BALANCE-ANALYSE:\")\n",
    "print(\"   âœ… Sehr ausgewogene Performance zwischen beiden Klassen\")\n",
    "print(\"   âœ… Keine starke Verzerrung zu einer Sentiment-Richtung\")\n",
    "print(\"   âœ… Minimaler Unterschied zwischen Precision und Recall\")\n",
    "print(\"   âœ… F1-Scores sind praktisch identisch (85% vs 86%)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“Š DURCHSCHNITTS-METRIKEN:\")\n",
    "print(\"   â€¢ Macro Average: 85% â†’ Ungewichteter Durchschnitt beider Klassen\")\n",
    "print(\"   â€¢ Weighted Average: 85% â†’ Nach KlassengrÃ¶ÃŸe gewichteter Durchschnitt\")\n",
    "print(\"   â†’ Beide identisch â†’ perfekt balanciertes Dataset!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ INTERPRETATION & BEWERTUNG:\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"ğŸŸ¢ SEHR GUTE PERFORMANCE:\")\n",
    "print(\"   â€¢ 85.5% Accuracy ist fÃ¼r Sentiment-Analyse sehr respektabel\")\n",
    "print(\"   â€¢ Balanced Performance zeigt robustes Modell\")\n",
    "print(\"   â€¢ Hyperparameter-Tuning hat sich gelohnt!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” VERGLEICH ZU VORHER:\")\n",
    "print(\"   â€¢ Erste Baseline: ~86% Accuracy\")\n",
    "print(\"   â€¢ Finale optimierte Version: 85.5% Accuracy\")\n",
    "print(\"   â€¢ GeringfÃ¼gig niedriger, aber mit optimaler Konfiguration\")\n",
    "print(\"   â€¢ Kreuzvalidierung sorgt fÃ¼r robustere SchÃ¤tzung\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ PRAKTISCHE BEDEUTUNG:\")\n",
    "print(\"   â€¢ Nur 14.5% Fehlerrate bei Sentiment-Erkennung\")\n",
    "print(\"   â€¢ ZuverlÃ¤ssige Klassifikation fÃ¼r praktische Anwendungen\")\n",
    "print(\"   â€¢ Gleich gute Performance bei positiven und negativen Reviews\")\n",
    "print(\"   â€¢ Modell zeigt keine systematischen Verzerrungen\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸš€ MÃ–GLICHE VERBESSERUNGEN:\")\n",
    "print(\"   â€¢ Mehr Trainingsdaten sammeln\")\n",
    "print(\"   â€¢ Erweiterte Textvorverarbeitung (z.B. Spelling-Korrektur)\")\n",
    "print(\"   â€¢ Andere Algorithmen testen (z.B. Random Forest, Neural Networks)\")\n",
    "print(\"   â€¢ Feature Engineering (z.B. Sentiment-Lexika, Word Embeddings)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
